# JX

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

r<-getOption("repos")
r["CRAN"]<-"http://cran.cnr.berkeley.edu/"
options(repos=r)

install.packages("tinytex")
library(tinytex)
library(tidyverse)

options(rstudio.markdownToHTML =
          function(inputFile, outputFile)
          {system(paste("pandoc", shQuote(inputFile), "-s --webtex -o", shQuote(outputFile)))})
```

### Section I & II: USA Soybeans Production Value & China’s Export Value

These two section of code showed the spatial polygons of soybeans production value in the USA and spatial polygons of China's export value. 

The spatial polygons could clearly show the soybeans production in the different states in the USA and the export value of different provinces of China. Therefore, these two models can be used to speculate the impact of the trade war on the specific areas of China and the United States.

```{r Geography of US-China Trade War}

# Install the required packages "sp"
install.packages("sp")

# Loading all the data/spatial data packages
library(sf)
library(raster)
library(dplyr)
library(spData)
library(spDataLarge)
library(readxl)
library(tmap)    # for static and interactive maps

# Install required "leaflet" packages to follow the steps after 
install.packages("leaflet")
library(leaflet) # for interactive maps
library(ggplot2) # tidyverse data visualization package
library(shiny)   # for web applications
library(rgdal)

# Geary and Moran test
library(spdep)
library(RColorBrewer)
library(classInt)
library(rgdal)
library(rgeos)


### Section 1: USA Soybeans Production Value
# Install required packages for section 1
install.packages("ggplot2")
install.packages("tidyverse")
install.packages("maps")
library(ggplot2)
library(tidyverse)
library(maps)

# Read USA map data
us_states <- map_data("state")
head(us_states)
# Read csv file 
mapdata <- read.csv("/Users/JGyffindor/Desktop/数据/state-soy-production.csv", header=TRUE, stringsAsFactors=FALSE)
mapdata %>% glimpse()

# First plot, ggplot the spatial polygons of the USA, include longitude and latitude.
ggplot() + geom_polygon( data=us_states, aes(x=long, y=lat, group = group),color="blue", fill="grey10" )

# Plot the soybeans production data in the polygons.
ggplot() + geom_polygon(data=us_states, aes(x=long, y=lat, group = group),color="blue", fill="grey92" ) + 
  geom_point(data=mapdata, aes(x=lon, y=lat, size = production), color="black") + 
  scale_size(name="", range = c(2, 20)) + 
  guides(size=guide_legend("Soy production value")) +
  theme_void()

# Save "soy production" as a png file.
ggsave("soy production.png", width=16.6,height=7.43,units="in")


### Section II: China's Export Value
library(readxl)
# Read China's export data information through the excel file
cn_info <- read_xlsx("/Users/JGyffindor/Desktop/数据/China export value.xlsx")
# Information by province
cn_info$Province <- stringr::str_trim(cn_info$Province) 

# Read China's OGR shape file
CN <- readOGR("/Users/JGyffindor/Desktop/数据/gadm36_CHN_shp/gadm36_CHN_1.shp")

library(sf)
cn_sf <- st_as_sf(CN) 

# Adding the price and year information to the map
# The price is export value and its numeric
cn_sf <- mutate(cn_sf, Price=as.numeric(cn_info$`Export Value`), Year=cn_info$Year)
# Set up a simple map which value is 0.1
cn_simple <- st_simplify(cn_sf, preserveTopology = T, 0.1) 
# Plot China's information with price/export value in a simple map 
plot(cn_simple['Price'])

# Join the spatial data
CN <- as(cn_simple, 'Spatial')

## Spatial test 1: 
# Shapiro testing the export value of China, see whether is normally distributed or not
shapiro.test(as.numeric(cn_info$`Export Value`))

# Create a data frame with near neibourhood by ID, and prepare for the testing
knn <- knearneigh(gCentroid(CN, byid = T), longlat = TRUE)
nbl <- knn2nb(knn)
nbl <- nb2listw(nbl)

## Spatial test 2:
# Geary test the autocorrolation of China's export value in different provinces.
geary.test(CN$Price, nbl)
geary.mc(CN$Price, nbl, 200)

# Moran test and plot for China exports value. 
moran.test(CN$Price,nbl)
moran.plot(CN$Price,nbl,pch=20)
```

### Section III: The USA Stock Market 

This section use the Quantmod to analyze two US major stock markets (Nasdaq and Dow Jones). 

```{r pressure, echo=FALSE}

# Install packages required before installing quantmod 
install.packages("TTR")

library(xts)
library(zoo)

# Install and library quantmod
if (!require("quantmod")) {
  install.packages("quantmod")
  library(quantmod)
}
library(quantmod)

# Install all required packages and complete the list of packages used
install.packages("rvest")
install.packages("xml2")
library(rvest)

install.packages("tidyverse")
library(tidyverse)
library(stringr)
library(forcats)

install.packages("lubridate")
library(lubridate)

install.packages("plotly")
library(plotly)
library(dplyr)

install.packages("PerformanceAnalytics")
library(PerformanceAnalytics)

# Setting options 
options("getSymbols.warning4.0"=FALSE)

# Get the data of Nasdaq index and view it 
getSymbols("^IXIC",from="2018-01-01",to="2019-08-30")

# Show the graph of Nasdaq stock index
IXIC%>%Ad()%>%chartSeries()

# Add the Bollinger Bands, volume, and Moving Average Convergence Divergence to Nasdaq stock 
# Then plot the full Nasdaq data with moving average, volume and bollinger
IXIC%>%chartSeries(TA="addBBands();addVo();addMACD()",from="2018-01-01",to="2019-08-30")

## Analysing the forecast of Nasdaq index
# Read Nasdaq (IXIC) csv input
IXIC=read.csv("/Users/JGyffindor/Desktop/金融数据分析-19 Autumn/IXIC.csv",header = T)
head(IXIC)

# Convert it into a time series [ts] by creating the function, where starting from January 2018.
# Reverse the 4th colume, which is the close value of IXIC
# Frequency=12 means 12 month a year
IXIC.ts=ts(rev(IXIC[,4]),start=c(2016,10),end=c(2019,10),freq = 12)
IXIC.ts

# Creat a data frame with closing stock prices value and log value are included
Nasdaq=data.frame(closing=IXIC.ts,lclosing=log(IXIC.ts))
save(Nasdaq,file = "Nasdaq.df.Rdata") #Save data frame
load("Nasdaq.df.Rdata") 

#Plotting the stock value from 2016.10 to 2019.10
# Year on abscissa, and closing price on ordinate
plot(Nasdaq$closing,main="Nasdaq stock prices(IXIC)",lwd=2,sub="October 2016 to October 2019",
     ylab="closing price")

# stl() is a function that decomposes the time series into seasonal
# Create Nasdaq dataframe by using the stl() function
Nasdaq.stl=stl(na.omit(Nasdaq$closing),s.window = "periodic")
plot(Nasdaq.stl,main = "Nasdaq stock decomposition") 

## Linear test 3: 
# Auto Regressive Integrated Moving Average (ARIMA) model to test the future trend of Nasdaq stock. 
# Install packages to address the forecast of stock market
install.packages("forecast")
library(forecast)

# Using the "Arima" method to predict the forecasting of Nasdaq stock for approximately 3 years. 
# h=32 specifies 32 months from October 2019 to June 2022, with a confidence interval equals to 95%
Nasdaq.f=forecast(Nasdaq.stl,method='arima',h=32,level=95)
plot(Nasdaq.f,ylab="stock price",xlab="year",sub="Forecast from October 2019 to June 2022")

### Dow Jones Index
# Get the data and showed the graph of Dowjones stock index
getSymbols("^DJI",from="2018-01-01",to="2019-08-30")
DJI%>%Ad()%>%chartSeries() # Plot Dow Jones index 

# Add the Bollinger Bands, volume, and Moving Average Convergence Divergence to Dow Jones stock 
# Plot Dow Jones Index with Bollinger Bands, moving average and volume added on.
DJI%>%chartSeries(TA="addBBands();addVo();addMACD()",from="2018-01-01",to="2019-08-30")

## Test 4: runs.test for testing the returns of DJI stock
# Read the stock price of DJI from csv file 
DJI <- read.csv("/Users/JGyffindor/Desktop/金融数据分析-19 Autumn/DJI.csv")

# Since the third column in the data has the DJI open stock prices, took the log value*100 as the returns.
DJI_ret <- 100*diff(log(DJI[,3])) 

# Omit the na values, and install required packages for testing
na.omit(DJI_ret)
install.packages("randtests")
library(randtests)

# Test the returns of DJI
runs.test(as.numeric(factor(DJI_ret > 0)))

```

Note: This project may be continue once the further research is conducted in the future.

The end! Thanks for watching!
